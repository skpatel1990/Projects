---
title: "Final Project"
author: "Sameer Patel"
date: "6/3/2020"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(Zelig)
library(zoom)
```

## Data Preparation  
We will begin by loading the data and using the summary() function to get a quick glance of it. We will also plot the raw data of bike crossings along the time period (1-Apr-2017 through 31-Oct-2017).

```{r}
dat<-read.csv("nyc_bb_bicyclist_counts.csv",stringsAsFactors = FALSE)
str(dat)
summary(dat)
print(head(dat))
g<-ggplot(dat,aes(x=Date,y=BB_COUNT)) + 
  geom_point() + 
  theme(axis.text.x=element_blank()) +
  ggtitle("Count of Bike Crossings Between April 1, 2017 and October 31, 2017") +
  ylab("Bike Count")
g
hist(dat$BB_COUNT,main="Frequency of Bike Crossings",xlab="Number of Crossings")
hist(dat$PRECIP,main="Frequency of Precipitation (in)",xlab="Inches of Precipitation",breaks=35)
hist(dat$HIGH_T,main="Frequency of High Temperature (F)",xlab="Temperature (F)")
hist(dat$LOW_T,main="Frequency of Low Temperature (F)",xlab="Temperature (F)")
```

## Fitting the data to a Poisson Model  
We will now incorporate the zelig() function from the Zelig package to fit the counts to the explanatory variables. Note that the specified family="poisson" uses a log link function by default.

```{r}
fit<-zelig(BB_COUNT~PRECIP+HIGH_T+LOW_T,model="poisson",data=dat,cite=FALSE)
summary(fit)
```

The Zelig function returns the same results as would be expected from the built-in function glm().

We can see that the Deviance Residuals are approximately normally distributed, but exhibit a little right-skewness since the median is not quite 0.  
Looking at the results, specifically the coefficients of the independent variables and their statistical significance, we can see that each coefficent estimate (for PRECIP, HIGH_T, and LOW_T) is statistically significantly different from 0, with PRECIP being the most influential explanatory variable. The coefficient for PRECIP being negative indicates an inverse relationship with bike crossings. The proceeding analysis will focus on precipitation, with the explanatory variables for LOW_T and HIGH_T fixed at their means.

A common way to interpret the results of a Poisson regression model is to compute the expected value (predicted mean) and predicted counts for the dependent variable based on the results of the analysis. Computing expected values and predicted counts requires setting accessory independent variables to some fixed value. Doing so allows us to evaluate how the independent variable of interest impacts changes in the results after recomputing quantities of interest.

The Zelig setx() function allows us to set independent variables to specific values in order to create profiles of interest. For exploring the effect of precipitation as aforementioned, we will establish two profiles: rain and shine (max and min precipitation, respectively). The other explanatory variables (HIGH_T and LOW_T) will be set equal to their means in both profiles. Though they still exhibit some influence on the predicted data, they are close enough to 0 and insignificant compared to the coefficient for PRECIP.

```{r}
rain<-setx(fit,PRECIP=max(PRECIP),
           HIGH_T=mean(HIGH_T),
           LOW_T=mean(LOW_T))
shine<-setx(fit,PRECIP=min(PRECIP),
           HIGH_T=mean(HIGH_T),
           LOW_T=mean(LOW_T))
```

The setx() function uses the variables identified in the formula generated by zelig() and sets the values of the explanatory variables to the selected values. The output returns a model matrix (with default unconditional prediction) based on the specified values for the explanatory variables.

The setx() function is used in conjunction with the sim() function (within the Zelig package).

The sim() function is used estimate the expected values and predicted counts of bike crossings, along with confidence intervals, for the profiles we defined. These quantities of interest are estimated using post-estimation (a posteriori) simulation. The process computes 1000 sets of expected values and predicted counts by simulating values for the model coefficients based on their estimated values, variances, and covariances.

```{r}
set.seed(2357)
counts.rain <- sim(fit, x=rain)
counts.shine <- sim(fit, x=shine)
summary(counts.rain)
summary(counts.shine)
```

The results display estimated means, standard deviations, medians (50%), and the 2.5 and 97.5 percentiles for the 1000 simulated expected values of bike crossings. Also presented are the same statistics calculated based on the predicted counts of bike crossings. Looking at the mean values for expected values of bike crossings between the rain and shine profiles, we can see that precipitation has a statistically significant effect on the dependent variable. The effect is quite pronounced: likely because I opted to use the maximum and minimum values of PRECIP for rain and shine, respectively. For continued analysis, more logical values, such as 75th quantile and 25th quantile, could be used to better estimate the data.

To visualize the data in a better way, we can create histograms of 1000 simulated counts for each profile. To do this, we use the simulation.matrix() function from the Zelig package to extract the simulated counts from the rain and shine profiles. 

```{r}
sim.counts.rain<-simulation.matrix(obj=counts.rain,which=summary(counts.rain)$titles[3])[,1]
sim.counts.shine<-simulation.matrix(obj=counts.shine,which=summary(counts.shine)$titles[3])[,1]

hist(sim.counts.rain,main="Predicted Counts of Bike Crossings (Rain)",xlab="Number of Crossings",breaks=20)
hist(sim.counts.shine,main="Predicted Counts of Bike Crossings (Shine)",xlab="Number of Crossings",breaks=20)
```

To continue visualizing the impact of precipitation on expected number of bike crossings, we can compute the expected value of bike crossing count repeatedly based on values of precipitation and present the results graphically. Below we show the expected value of the count of bike crossings, along with a 95% confidence interval, as a function of precipitation, whilst keeping HIGH_T and LOW_T at the means specified in the profiles we created.

To generate this data, we can use a for loop along with the aforementioned setx() and sim() functions for data points within the range of observed PRECIP data. For help in data visualization, the "zoom" package was added to the library, which allows panning/zooming on plotted figures in R.

```{r}
set.seed(2357)
prec_pts<-seq(min(dat$PRECIP),max(dat$PRECIP),by=0.1)
results<-matrix(data=NA,length(prec_pts),4)

for(i in 1:length(prec_pts)){
  prec<-setx(fit,PRECIP=prec_pts[i],
           HIGH_T=mean(HIGH_T),
           LOW_T=mean(LOW_T))
  precvals<-sim(fit,x=prec)
  
  results[i,1]<-precvals$stats$'Expected Values: E(Y|X)'[,3]
  results[i,2]<-precvals$stats$'Expected Values: E(Y|X)'[,4]
  results[i,3]<-precvals$stats$'Expected Values: E(Y|X)'[,5]
  results[i,4]<-prec_pts[i]
}

plot(results[,4],
     results[,1],
     xlab="Precipitation (in)",
     ylab="Expected Value (count)",
     main="Expected Value of Bike Crossings vs. Precipitation (in)"
)
abline(h=seq(500,2500,500),col="gray80")
lines(results[,4],results[,1],col="red",lwd=1)
lines(results[,4],results[,2],col="blue",lwd=1,lty=2)
lines(results[,4],results[,3],col="blue",lwd=1,lty=2)
legend("topright",
       legend=c("Expected Value","95% Confidence Interval"),
       col=c("red","blue"),
       lty=1:2,
       cex=0.8
)
# zm()
```

From the graph, we can see a relatively tight window representing the 95% confidence interval for each of the values of precipitation from our simulated profile. This indicates a good fit of the data to the Generalized Poisson Model employed in our data analysis.